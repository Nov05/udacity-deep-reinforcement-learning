{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-agent DDPG for Solving Unity's \"Tennis\" Problem\n",
    "\n",
    "In this notebook we report how we used Multi-agent Deep Deterministic Policy Gradient (MADDPG) algorithm to solve a modified version of Unitfy's \"Tennis\" environment, where we need to control two agents to play tennis in a 3D environment.\n",
    "\n",
    "This notebook contains all the code for training and running the agent.\n",
    "\n",
    "A demo of a pair of trained agents is shown in the gif below:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "The dependencies can be set up by following the instructions from the [DRLND](https://github.com/udacity/deep-reinforcement-learning#dependencies) repo. Once it's done, the following imports should work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\github\\udacity-deep-reinforcement-learning\\python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\guido\\miniconda3\\envs\\drlnd_py310\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd ../../python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import itertools\n",
    "import math\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, List, Tuple, Optional, Generator\n",
    "import random\n",
    "import os\n",
    "import wandb\n",
    "\n",
    "import numpy\n",
    "import torch\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that to make GPU training work on our machine, the following version of PyTorch is used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version: 2.5.1; Cuda available: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Version: {torch.__version__}; Cuda available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we also need to download the pre-built Unity environment, which can be downloaded for different platforms:\n",
    "\n",
    "- Linux: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P3/Tennis/Tennis_Linux.zip)\n",
    "- Mac OSX: [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P3/Tennis/Tennis.app.zip)\n",
    "- Windows (32-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P3/Tennis/Tennis_Windows_x86.zip)\n",
    "- Windows (64-bit): [click here](https://s3-us-west-1.amazonaws.com/udacity-drlnd/P3/Tennis/Tennis_Windows_x86_64.zip)\n",
    "\n",
    "Once downloaded and extracted, please set the path below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV_PATH = '..\\data\\Tennis_Windows_x86_64\\Tennis.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If set up correctly, we should be able to initialize the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ‘‰ UnityEnvironment seed: 0\n",
      "ðŸŸ¢ RpcCommunicator at port 5005 is initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "class ParallelEnv:\n",
    "    \"\"\"A simple wrapper for the environment with parallel agents.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._env = UnityEnvironment(file_name=ENV_PATH, no_graphics=True)\n",
    "\n",
    "        env_info = self._env.reset(train_mode=True)[self._brain_name]\n",
    "        self.num_agents = len(env_info.agents)\n",
    "\n",
    "    @property\n",
    "    def _brain_name(self):\n",
    "        return self._env.brain_names[0]\n",
    "\n",
    "    @property\n",
    "    def _brain(self):\n",
    "        return self._env.brains[self._brain_name]\n",
    "\n",
    "    @property\n",
    "    def action_dim(self) -> int:\n",
    "        \"\"\"The size of a action vector.\"\"\"\n",
    "        return self._brain.vector_action_space_size\n",
    "\n",
    "    @property\n",
    "    def action_scale(self) -> float:\n",
    "        \"\"\"The scale of action values.\n",
    "\n",
    "        Each dimension of the action vector lies in range [-scale, scale].\n",
    "\n",
    "        \"\"\"\n",
    "        return 1.0\n",
    "\n",
    "    def sample_action(self) -> numpy.array:\n",
    "        \"\"\"Sample an action vector uniformly at random.\"\"\"\n",
    "        return numpy.random.uniform(\n",
    "            low=-self.action_scale,\n",
    "            high=self.action_scale,\n",
    "            size=(self.num_agents, self.action_dim),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def state_dim(self) -> int:\n",
    "        \"\"\"The size of a state vector.\"\"\"\n",
    "        return self._brain.vector_observation_space_size * self._brain.num_stacked_vector_observations\n",
    "\n",
    "    def reset(self, train_mode=True) -> numpy.array:\n",
    "        \"\"\"Reset the environment and returns the initial state.\"\"\"\n",
    "        env_info = self._env.reset(train_mode=train_mode)[self._brain_name]\n",
    "        init_state = env_info.vector_observations\n",
    "        assert init_state.shape == (self.num_agents, self.state_dim)\n",
    "        return init_state\n",
    "\n",
    "    def step(\n",
    "        self, actions: numpy.array\n",
    "    ) -> Tuple[numpy.array, numpy.array, numpy.array]:\n",
    "        \"\"\"Take a step with the given actions.\n",
    "\n",
    "        Returns a tuple of (states, rewards, done-flags) for all parallel agents.\n",
    "\n",
    "        \"\"\"\n",
    "        assert actions.shape == (self.num_agents, self.action_dim)\n",
    "        env_info = self._env.step(actions)[self._brain_name]\n",
    "        return (\n",
    "            numpy.array(env_info.vector_observations, dtype=numpy.float32),\n",
    "            numpy.array(env_info.rewards, dtype=numpy.float32),\n",
    "            numpy.array(env_info.local_done, dtype=bool),\n",
    "        )\n",
    "\n",
    "    def close(self) -> None:\n",
    "        \"\"\"Closes the environment.\"\"\"\n",
    "        self._env.close()\n",
    "\n",
    "\n",
    "env = ParallelEnv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment description\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net. If an agent hits the ball over the net, it receives a reward of +0.1. If an agent lets a ball hit the ground or hits the ball out of bounds, it receives a reward of -0.01. Thus, the goal of each agent is to keep the ball in play.\n",
    "\n",
    "The observation space consists of 8 variables corresponding to the position and velocity of the ball and racket. Each agent receives its own, local observation. Two continuous actions are available, corresponding to movement toward (or away from) the net, and jumping.\n",
    "\n",
    "The task is considered \"solved\" when the agents get an average score of +0.5 (over 100 consecutive episodes, after taking the maximum over both agents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Action dimension: 2\n",
      "States dimension: 24\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of agents: {env.num_agents}')\n",
    "print(f'Action dimension: {env.action_dim}')\n",
    "print(f'States dimension: {env.state_dim}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology & Implementation\n",
    "\n",
    "To solve this problem, we experimented with MADDPG as described by Lowe et al. (2017). Compared DDPG as described by Lillicrap et al. (2015), we allow critics access to observations and actions from all agents, so that it can better guide the actors which only have access to their local observations.\n",
    "\n",
    "As described in the paper, we let each agent to have its own actor and critic networks not shared with each other. For this simple problem, using MADDPG doesn't necessarily seem to improve convergence speed, but it's interesting to see how agents with different behaviors are able to cooperate and bounce the ball back and forth.\n",
    "\n",
    "Additionally, we also incorporate extensions to DDPG from TD3 (Fujimoto et al. 2018), namely:\n",
    "\n",
    "- Clipped double Q-Learning for actor-critic\n",
    "- Delayed policy updates\n",
    "- Target policy smoothing regularization\n",
    "\n",
    "The incorporation of TD3 tricks into MADDPG has also been explored by Ackermann et al. (2019), which managed to achieve better result in their tests. They called the approach MATD3.\n",
    "\n",
    "Additionally, we also used prioritized experience replay as described by Schaul et al. (2015)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-parameters\n",
    "\n",
    "The hyper-parameters we used is shown as the default values in the following data class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgentConfig(horizon_length=10000, replay_buffer_size=100000, batch_size=256, critic_lr=0.0001, actor_lr=0.0001, exploration_noise=0.1, policy_noise=0.2, policy_noise_clip=0.5, policy_update_freq=2, discount_factor=0.99, soft_update_factor=0.005, pure_exploration_steps=10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class AgentConfig:\n",
    "    horizon_length: int = 10000\n",
    "    replay_buffer_size: int = 100_000\n",
    "    batch_size: int = 256\n",
    "    critic_lr: float = 1e-4\n",
    "    actor_lr: float = 1e-4\n",
    "    exploration_noise: float = 0.1\n",
    "    policy_noise: float = 0.2\n",
    "    policy_noise_clip: float = 0.5\n",
    "    policy_update_freq: int = 2\n",
    "    discount_factor: float = 0.99\n",
    "    soft_update_factor: float = 0.005\n",
    "    pure_exploration_steps: int = 10_000\n",
    "    \n",
    "AgentConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prioritized experience replay\n",
    "Here we use prioritized experience replay as described in Schaul et al. (2015). Specifically, we implemented the proportional priorization variant with the sum-tree data structure.\n",
    "\n",
    "The code for the replay buffer is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer:\n",
    "    \"\"\"A proportionally prioritized replay buffer implemented with sum-tree.\"\"\"\n",
    "\n",
    "    _curr_index: int\n",
    "    _size: int\n",
    "    _max_priority: float\n",
    "    _sum_tree: List[float]\n",
    "    _priorities: List[float]\n",
    "    _samples: List[Any]\n",
    "\n",
    "    def __init__(self, buffer_size: int):\n",
    "        assert buffer_size > 1\n",
    "        self._curr_index = 0\n",
    "        self._size = 0\n",
    "        self._max_priority = 1.0\n",
    "        self._sum_tree = [0] * (2 ** (math.floor(math.log2(buffer_size - 1)) + 1) - 1)\n",
    "        self._priorities = [0] * buffer_size\n",
    "        self._samples = [None] * buffer_size\n",
    "\n",
    "    def _ancestor_indices(self, sample_index: int) -> Generator[int, None, None]:\n",
    "        assert 0 <= sample_index <= len(self._samples)\n",
    "        index = sample_index + len(self._sum_tree)\n",
    "        while index > 0:\n",
    "            index = (index - 1) // 2\n",
    "            yield index\n",
    "\n",
    "    @staticmethod\n",
    "    def _children_indices(index: int) -> Tuple[int, int]:\n",
    "        # Note that it could go out-of-bounds for the sum tree array\n",
    "        left_index = index * 2 + 1\n",
    "        right_index = left_index + 1\n",
    "        return left_index, right_index\n",
    "\n",
    "    def _set_priority(self, sample_index: int, priority: float):\n",
    "        assert priority > 0, \"Weights must be non-negative\"\n",
    "        delta = priority - self._priorities[sample_index]\n",
    "        self._priorities[sample_index] = priority\n",
    "        for index in self._ancestor_indices(sample_index):\n",
    "            self._sum_tree[index] += delta\n",
    "\n",
    "        self._max_priority = max(self._max_priority, priority)\n",
    "\n",
    "    def _set_sample(self, sample_index: int, sample: Any, priority: float):\n",
    "        self._set_priority(sample_index, priority)\n",
    "        self._samples[sample_index] = sample\n",
    "\n",
    "    class _SampleHandle:\n",
    "        \"\"\"A handle that allows access to the value and priority of a sample in the buffer.\"\"\"\n",
    "\n",
    "        _parent: \"PrioritizedReplayBuffer\"\n",
    "        _index: int\n",
    "\n",
    "        def __init__(self, parent: \"PrioritizedReplayBuffer\", index: int):\n",
    "            assert 0 <= index <= len(parent._samples)\n",
    "            self._parent = parent\n",
    "            self._index = index\n",
    "\n",
    "        @property\n",
    "        def value(self) -> Any:\n",
    "            \"\"\"The value of the sample.\"\"\"\n",
    "            return self._parent._samples[self._index]\n",
    "\n",
    "        @property\n",
    "        def priority(self) -> float:\n",
    "            \"\"\"The priority of the sample.\"\"\"\n",
    "            return self._parent._priorities[self._index]\n",
    "\n",
    "        @property\n",
    "        def sample_probability(self) -> float:\n",
    "            \"\"\"The probability of sampling this item.\"\"\"\n",
    "            return self.priority / self._parent.priority_sum\n",
    "\n",
    "        @priority.setter\n",
    "        def priority(self, priority: float) -> None:\n",
    "            \"\"\"Modify the priority of the sample.\"\"\"\n",
    "            self._parent._set_priority(self._index, priority)\n",
    "\n",
    "        def reset(self, value: Any, priority: float):\n",
    "            \"\"\"Modify both the value and the priority of the sample.\"\"\"\n",
    "            self._parent._set_sample(self._index, value, priority)\n",
    "\n",
    "    def add(self, value: Any, priority: Optional[float] = None) -> None:\n",
    "        \"\"\"Add a new sample.\"\"\"\n",
    "        # By default, the current maximum priority is used for new samples to make sure they get picked at least once\n",
    "        if priority is None:\n",
    "            priority = self._max_priority\n",
    "\n",
    "        self._SampleHandle(self, self._curr_index).reset(value, priority)\n",
    "\n",
    "        buffer_size = len(self._samples)\n",
    "        self._curr_index = (self._curr_index + 1) % buffer_size\n",
    "        self._size = min(self._size + 1, buffer_size)\n",
    "\n",
    "    @property\n",
    "    def priority_sum(self) -> float:\n",
    "        \"\"\"The sum of priority values of all samples in the buffer.\n",
    "\n",
    "        This is used to compute sample probabilities.\n",
    "\n",
    "        \"\"\"\n",
    "        return self._sum_tree[0]\n",
    "\n",
    "    def sample_single(self, query: Optional[float] = None) -> _SampleHandle:\n",
    "        \"\"\"Draw a sample.\n",
    "\n",
    "        The query parameter is a float in [0, 1] for stratified sampling.\n",
    "\n",
    "        \"\"\"\n",
    "        assert self.priority_sum > 0.0, \"Nothing has been added\"\n",
    "\n",
    "        if query is None:\n",
    "            query = random.random()\n",
    "\n",
    "        assert 0.0 <= query <= 1.0\n",
    "        target = self.priority_sum * query\n",
    "        index = 0\n",
    "        while True:\n",
    "            assert 0.0 <= target <= self._sum_tree[index]\n",
    "            index_l, index_r = self._children_indices(index)\n",
    "\n",
    "            assert (index_l < len(self._sum_tree)) == (index_r < len(self._sum_tree))\n",
    "            if index_l >= len(self._sum_tree):\n",
    "                # We've reached the leaves when both left & right indices are out of range for the tree structure.\n",
    "                # Offset both indices to get the indices into the sample list before breaking.\n",
    "                index_l -= len(self._sum_tree)\n",
    "                index_r -= len(self._sum_tree)\n",
    "                break\n",
    "\n",
    "            # If the target is smaller than the sum of the left subtree, go left; otherwise go right\n",
    "            sum_l = self._sum_tree[index_l]\n",
    "            if target <= sum_l:\n",
    "                index = index_l\n",
    "            else:\n",
    "                target -= sum_l\n",
    "                index = index_r\n",
    "\n",
    "        assert index_l < len(self._priorities)\n",
    "        if target <= self._priorities[index_l]:\n",
    "            index = index_l\n",
    "        else:\n",
    "            assert index_r < len(self._priorities)\n",
    "            index = index_r\n",
    "\n",
    "        return self._SampleHandle(self, index)\n",
    "\n",
    "    def sample_batch(self, batch_size: int) -> List[_SampleHandle]:\n",
    "        \"\"\"Draw a stratified batch of samples with the given size.\"\"\"\n",
    "        # Divide the sum range into batch_size buckets, and do a weighted sampling from each bucket.\n",
    "        end_points = numpy.linspace(0.0, 1.0, batch_size + 1).tolist()\n",
    "        return [\n",
    "            self.sample_single(query=numpy.random.uniform(l, r))\n",
    "            for l, r in zip(end_points[:-1], end_points[1:])\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return self._size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor-critic\n",
    "\n",
    "Like in TD3 (Fujimoto et al. 2018), we have one actor / policy network and a pair of critic / Q networks for each agent.\n",
    "\n",
    "Andrychowicz et al. (2020) suggested that it's helpful to initialize the final layer of the actor network with small weights so that initially actions depend little on the observations. They suggested doing the same for the critic network doesn't seem to be useful, but it turns out that for this particular problem it does seem to help, too. This is probably because during the initial training state the expected accumulative reward is always close to 0 anyways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        state_dim: int,\n",
    "        action_dim: int,\n",
    "        action_scale=1.0,\n",
    "        hidden_dims: Tuple[int, ...] = (256, 256),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.action_scale = action_scale\n",
    "        self.fcs = torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.Linear(in_size, out_size)\n",
    "                for in_size, out_size in zip(\n",
    "                    (state_dim,) + hidden_dims, hidden_dims + (action_dim,)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            self.fcs[-1].weight.divide_(100.)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = state\n",
    "        for i, fc in enumerate(self.fcs, start=1):\n",
    "            x = fc(x)\n",
    "            if i != len(self.fcs):\n",
    "                x = torch.relu(x)\n",
    "\n",
    "        x = torch.tanh(x) * self.action_scale\n",
    "        return x\n",
    "\n",
    "\n",
    "class CriticNet(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_agents: int,\n",
    "        state_dim: int,\n",
    "        action_dim: int,\n",
    "        hidden_dims: Tuple[int, ...] = (256, 256),\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.fcs = torch.nn.ModuleList(\n",
    "            [\n",
    "                torch.nn.Linear(in_size, out_size)\n",
    "                for in_size, out_size in zip(\n",
    "                    (num_agents * (state_dim + action_dim),) + hidden_dims,\n",
    "                    hidden_dims + (1,)\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            self.fcs[-1].weight.divide_(100.)\n",
    "\n",
    "\n",
    "    def forward(self, states: List[torch.FloatTensor], actions: List[torch.FloatTensor]):\n",
    "        x = torch.cat(states + actions, dim=1)\n",
    "        for i, fc in enumerate(self.fcs, start=1):\n",
    "            x = fc(x)\n",
    "            if i != len(self.fcs):\n",
    "                x = torch.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class CriticPair(torch.nn.Module):\n",
    "    \"\"\"A simple wrapper for a pair of critics.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_agents: int,\n",
    "        state_dim: int,\n",
    "        action_dim: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self._critics = torch.nn.ModuleList(\n",
    "            [CriticNet(num_agents, state_dim, action_dim) for _ in range(2)]\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, index: int) -> torch.nn.Module:\n",
    "        return self._critics[index]\n",
    "\n",
    "    def forward(self, state, action):\n",
    "        return self._critics[0](state, action), self._critics[1](state, action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MATD3\n",
    "\n",
    "Here the agents are trained using the MADDPG framework, while also incorporating extensions introduced by TD3.\n",
    "\n",
    "Like in TD3, we start with 10,000 steps of \"pure exploration\", during which the agents take steps completely at random. This seems to cause the agents to take more unnecessary and eradic actions, but does seem to help with exploration and prevent stagnation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAgent:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    env: ParallelEnv\n",
    "    config: AgentConfig\n",
    "\n",
    "    replay_buffers: List[PrioritizedReplayBuffer]\n",
    "\n",
    "    critics_local: List[CriticPair]\n",
    "    critics_target: List[CriticPair]\n",
    "    actors_local: List[ActorNet]\n",
    "    actors_target: List[ActorNet]\n",
    "\n",
    "    critic_optimizers: List[torch.optim.Optimizer]\n",
    "    actor_optimizers: List[torch.optim.Optimizer]\n",
    "\n",
    "    t_step: int\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env: ParallelEnv,\n",
    "        config: Optional[AgentConfig] = None,\n",
    "        steps_offset: int = 0\n",
    "    ):\n",
    "        self.env = env\n",
    "        self.config = config or AgentConfig()\n",
    "\n",
    "        self.replay_buffers = [\n",
    "            PrioritizedReplayBuffer(self.config.replay_buffer_size)\n",
    "            for _ in range(self.env.num_agents)\n",
    "        ]\n",
    "\n",
    "        self.critics_local = [\n",
    "            CriticPair(\n",
    "                env.num_agents,\n",
    "                env.state_dim,\n",
    "                env.action_dim,\n",
    "            ).to(self.device)\n",
    "            for _ in range(self.env.num_agents)\n",
    "        ]\n",
    "        self.actors_local = [\n",
    "            ActorNet(\n",
    "                env.state_dim,\n",
    "                env.action_dim,\n",
    "                action_scale=env.action_scale,\n",
    "            ).to(self.device)\n",
    "            for _ in range(self.env.num_agents)\n",
    "        ]\n",
    "\n",
    "        self.critics_target = copy.deepcopy(self.critics_local)\n",
    "        for m in self.critics_target:\n",
    "            m.eval()\n",
    "\n",
    "        self.actors_target = copy.deepcopy(self.actors_local)\n",
    "        for m in self.actors_target:\n",
    "            m.eval()\n",
    "\n",
    "        self.critic_optimizers = [\n",
    "            torch.optim.Adam(\n",
    "                critics.parameters(),\n",
    "                lr=self.config.critic_lr,\n",
    "            )\n",
    "            for critics in self.critics_local\n",
    "        ]\n",
    "        self.actor_optimizers = [\n",
    "            torch.optim.Adam(\n",
    "                actor.parameters(),\n",
    "                lr=self.config.actor_lr,\n",
    "            )\n",
    "            for actor in self.actors_local\n",
    "        ]\n",
    "\n",
    "        self.t_step = 0\n",
    "        self.steps_offset = steps_offset\n",
    "        wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project=\"udacity-drlnd-matd3-unity-tennis\",\n",
    "            config=self.config\n",
    "            )\n",
    "\n",
    "    def _choose_action_inner(\n",
    "        self,\n",
    "        actor: ActorNet,\n",
    "        states: torch.FloatTensor,\n",
    "        *,\n",
    "        policy_noise=False,\n",
    "        exploration_noise=False,\n",
    "    ) -> numpy.array:\n",
    "        assert not (policy_noise and exploration_noise)\n",
    "\n",
    "        actions = actor(states)\n",
    "        if policy_noise:\n",
    "            # Introduce policy noise to smooth the critic fit\n",
    "            actions += torch.clamp(\n",
    "                torch.randn_like(actions) * self.config.policy_noise,\n",
    "                min=-self.config.policy_noise_clip,\n",
    "                max=self.config.policy_noise_clip,\n",
    "            )\n",
    "\n",
    "        if exploration_noise:\n",
    "            # Introduce noise for exploration\n",
    "            actions += torch.randn_like(actions) * self.config.exploration_noise\n",
    "\n",
    "        return actions.clamp(\n",
    "            min=-self.env.action_scale,\n",
    "            max=self.env.action_scale,\n",
    "        )\n",
    "\n",
    "    def choose_action(\n",
    "        self, all_states: List[numpy.array], *, exploration_noise=False\n",
    "    ) -> numpy.array:\n",
    "        \"\"\"Choose actions for the given batch of states.\"\"\"\n",
    "        assert len(all_states) == len(self.actors_local)\n",
    "        all_actions = []\n",
    "        for actor, states in zip(self.actors_local, all_states):\n",
    "            actor.eval()\n",
    "            with torch.no_grad():\n",
    "                states = torch.from_numpy(states).float().to(self.device)\n",
    "                actions = self._choose_action_inner(\n",
    "                    actor, states, exploration_noise=exploration_noise\n",
    "                ).cpu().numpy()\n",
    "\n",
    "            actor.train()\n",
    "            all_actions.append(actions)\n",
    "        \n",
    "        return numpy.array(all_actions)\n",
    "\n",
    "    def _step_learn(self, agent_index):\n",
    "        if (\n",
    "            len(self.replay_buffers[agent_index]) < self.config.batch_size\n",
    "            # Only start learning after the pure exploration phase has ended\n",
    "            or self.t_step <= self.config.pure_exploration_steps\n",
    "        ):\n",
    "            return\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # Sample a batch of experiences\n",
    "            replay_buffer = self.replay_buffers[agent_index]\n",
    "            experiences = replay_buffer.sample_batch(self.config.batch_size)\n",
    "            states, actions, rewards, next_states, dones = [\n",
    "                [\n",
    "                    torch.from_numpy(numpy.vstack([\n",
    "                        v[i] for v in col\n",
    "                    ])).to(dtype=torch.float, device=self.device)\n",
    "                    for i in range(self.env.num_agents)\n",
    "                ]\n",
    "                for col in zip(*[e.value for e in experiences])\n",
    "            ]\n",
    "\n",
    "            # Calculate importance sampling weights from sampling probs (for simply not using alpha / beta here)\n",
    "            sample_probs = torch.from_numpy(\n",
    "                numpy.vstack([e.sample_probability for e in experiences])\n",
    "            ).to(device=self.device, dtype=torch.float)\n",
    "            sample_weights = 1.0 / (sample_probs * len(replay_buffer))\n",
    "\n",
    "            # Calculate target Q values\n",
    "            assert len(self.actors_target) == len(next_states)\n",
    "            next_actions = [\n",
    "                self._choose_action_inner(\n",
    "                    actor, ns, policy_noise=True\n",
    "                )\n",
    "                for actor, ns in zip(self.actors_target, next_states)\n",
    "            ]\n",
    "            q_target = rewards[agent_index] + (\n",
    "                (1.0 - dones[agent_index])\n",
    "                * self.config.discount_factor\n",
    "                * torch.minimum(*self.critics_target[agent_index](next_states, next_actions))\n",
    "            )\n",
    "\n",
    "        critic_losses = sum(\n",
    "            torch.nn.functional.mse_loss(q, q_target, reduction=\"none\")\n",
    "            for q in self.critics_local[agent_index](states, actions)\n",
    "        )\n",
    "\n",
    "        # Update local critics\n",
    "        critic_loss = torch.mean(critic_losses * sample_weights)\n",
    "        if torch.isnan(critic_loss).cpu().item():\n",
    "            raise RuntimeError(\"NaN loss\")\n",
    "        \n",
    "        wandb.log({f'critic_loss_{agent_index}': critic_loss}, \n",
    "                  step=self.t_step+self.steps_offset)\n",
    "        self.critic_optimizers[agent_index].zero_grad()\n",
    "        critic_loss.backward()\n",
    "        self.critic_optimizers[agent_index].step()\n",
    "\n",
    "        # Update sampling priorities\n",
    "        with torch.no_grad():\n",
    "            new_sample_priorities = critic_losses.sqrt().squeeze().cpu().numpy()\n",
    "            assert len(experiences) == len(new_sample_priorities)\n",
    "            for e, p in zip(experiences, new_sample_priorities):\n",
    "                e.priority = p\n",
    "\n",
    "        # Periodically update local actor as well as target networks\n",
    "        if self.t_step % self.config.policy_update_freq == 0:\n",
    "            # Update local actor to step towards maximizing the (first) local critic value\n",
    "            actor_loss = -torch.mean(\n",
    "                self.critics_local[agent_index][0](states, [\n",
    "                    actions[i]\n",
    "                    if i != agent_index\n",
    "                    else self.actors_local[agent_index](states[agent_index])\n",
    "                    for i in range(self.env.num_agents)\n",
    "                ])\n",
    "            )\n",
    "            if torch.isnan(actor_loss).cpu().item():\n",
    "                raise RuntimeError(\"NaN loss\")\n",
    "            \n",
    "            wandb.log({f'actor_loss_{agent_index}': actor_loss}, \n",
    "                      step=self.t_step+self.steps_offset)\n",
    "            self.actor_optimizers[agent_index].zero_grad()\n",
    "            actor_loss.backward()\n",
    "            self.actor_optimizers[agent_index].step()\n",
    "\n",
    "            # Soft-update target critics & actor\n",
    "            tau = self.config.soft_update_factor\n",
    "            for local_net, target_net in [\n",
    "                (self.actors_local[agent_index], self.actors_target[agent_index]),\n",
    "                (self.critics_local[agent_index], self.critics_target[agent_index]),\n",
    "            ]:\n",
    "                for local_param, target_param in zip(\n",
    "                    local_net.parameters(), target_net.parameters()\n",
    "                ):\n",
    "                    target_param.data.copy_(\n",
    "                        tau * local_param.data + (1.0 - tau) * target_param.data\n",
    "                    )\n",
    "\n",
    "    def _train_episode(self):\n",
    "        states = self.env.reset()\n",
    "        episode_scores = numpy.zeros(self.env.num_agents, dtype=float)\n",
    "        for _ in range(self.config.horizon_length):\n",
    "            if numpy.any(numpy.isnan(states)):\n",
    "                print(\"\\nNaN State, episode terminated\")\n",
    "                break\n",
    "\n",
    "            # If we're in pure exploration phase, sample an action uniformly at random\n",
    "            if self.t_step <= self.config.pure_exploration_steps:\n",
    "                actions = self.env.sample_action()\n",
    "            else:\n",
    "                actions = self.choose_action(states, exploration_noise=True)\n",
    "                if numpy.any(numpy.isnan(actions)):\n",
    "                    raise RuntimeError(\"NaN Action\")\n",
    "\n",
    "            next_states, rewards, dones = self.env.step(actions)\n",
    "            if numpy.any(numpy.isnan(rewards)):\n",
    "                print(\"\\nNaN Reward, episode terminated\")\n",
    "                break\n",
    "\n",
    "            for i, replay_buffer in enumerate(self.replay_buffers):\n",
    "                replay_buffer.add((states, actions, rewards, next_states, dones))\n",
    "\n",
    "            self.t_step += 1\n",
    "            for i in range(self.env.num_agents):\n",
    "                self._step_learn(i)\n",
    "\n",
    "            states = next_states\n",
    "            episode_scores += rewards\n",
    "            if numpy.any(dones):\n",
    "                break\n",
    "\n",
    "        return numpy.max(episode_scores)\n",
    "\n",
    "    def train(\n",
    "        self,\n",
    "        max_steps=1_000_000,\n",
    "        solved_score=0.5,\n",
    "    ):\n",
    "        \"\"\"Train the agent until the max training steps or the solved score is reached.\n",
    "\n",
    "        Returns a list of (step, score) pairs, one for each training episode.\n",
    "\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        scores_window = collections.deque(maxlen=100)\n",
    "        solved = False\n",
    "        max_windowed_average_score = float(\"-inf\")\n",
    "\n",
    "        stop_step = self.t_step + max_steps\n",
    "        while self.t_step < stop_step:\n",
    "            average_score = self._train_episode()\n",
    "            scores.append((self.t_step, average_score))\n",
    "            scores_window.append(average_score)\n",
    "            windowed_average_score = numpy.mean(scores_window)\n",
    "            wandb.log({'episodic_return_train': average_score}, \n",
    "                      step=self.t_step+self.steps_offset)  ## w&b logs\n",
    "            print(\n",
    "                f\"\\rEpisode {len(scores)}\\tStep {self.t_step}\\tScore: {average_score:.2f}\\t\"\n",
    "                f\"Windowed average Score: {windowed_average_score:.2f}\",\n",
    "                end=\"\\n\" if len(scores) % 500 == 0 else \"\",\n",
    "            )\n",
    "\n",
    "            if not solved and windowed_average_score >= solved_score:\n",
    "                print(\n",
    "                    f\"\\nReached average score of {windowed_average_score:.2f} between \"\n",
    "                    f\"episode {len(scores) - len(scores_window) + 1} and episode {len(scores)}\"\n",
    "                )\n",
    "                solved = True\n",
    "\n",
    "            # Save the best model so far\n",
    "            if average_score >= windowed_average_score > max_windowed_average_score:\n",
    "                self.save()\n",
    "                max_windowed_average_score = windowed_average_score\n",
    "\n",
    "        return scores\n",
    "\n",
    "    def run_episode(self, horizon_length=10000):\n",
    "        \"\"\"Run one episode using the agent.\"\"\"\n",
    "        states = self.env.reset(train_mode=False)\n",
    "        score = 0.0\n",
    "        for _ in range(horizon_length):\n",
    "            if numpy.any(numpy.isnan(states)):\n",
    "                print(\"\\nNaN State, episode terminated\")\n",
    "                break\n",
    "\n",
    "            actions = self.choose_action(states)\n",
    "            if numpy.any(numpy.isnan(actions)):\n",
    "                raise RuntimeError(\"NaN Action\")\n",
    "\n",
    "            next_states, rewards, dones = self.env.step(actions)\n",
    "            if numpy.any(numpy.isnan(rewards)):\n",
    "                print(\"\\nNaN Reward, episode terminated\")\n",
    "                break\n",
    "\n",
    "            states = next_states\n",
    "            score += numpy.sum(rewards)\n",
    "            if numpy.any(dones):\n",
    "                break\n",
    "\n",
    "        return score / self.env.num_agents\n",
    "    \n",
    "    def save(self, filepath='experiments/maddpg-unity-tennis/'):\n",
    "        \"\"\"Save the trained model.\"\"\"\n",
    "        for i in range(self.env.num_agents):\n",
    "            torch.save(self.actors_local[i].state_dict(), f\"{filepath}actor{i}.pt\")\n",
    "            torch.save(self.critics_local[i].state_dict(), f\"{filepath}critics{i}.pt\")\n",
    "    \n",
    "    def load(self, steps_offset:int=0, filepath='experiments/maddpg-unity-tennis/'):\n",
    "        self.t_step, self.steps_offset = 0, steps_offset\n",
    "        \"\"\"Load the previously trained model.\"\"\"\n",
    "        for i in range(self.env.num_agents):\n",
    "            self.actors_local[i].load_state_dict(torch.load(f\"{filepath}actor{i}.pt\"))\n",
    "            self.critics_local[i].load_state_dict(torch.load(f\"{filepath}critics{i}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filepath = 'experiments/maddpg-unity-tennis/'\n",
    "\n",
    "def save_scores(scores):\n",
    "    filename = f\"{filepath}scores.pkl\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(scores, f)\n",
    "\n",
    "def load_scores():\n",
    "    filename = f\"{filepath}scores.pkl\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        loaded_list = pickle.load(f)\n",
    "    return loaded_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & Evaluate\n",
    "\n",
    "With everything set up, we're now ready to train the agent. Here we train the agent for 1 million steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()\n",
    "# os.environ['WANDB_MODE'] = 'disabled'  ## log training process with W&B if uncommented\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'udacity-drlnd-matd3-unity-tennis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find udacity-drlnd-matd3-unity-tennis.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnov05\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\github\\udacity-deep-reinforcement-learning\\python\\wandb\\run-20241114_234503-8yg7m0ph</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nov05/udacity-drlnd-matd3-unity-tennis/runs/8yg7m0ph' target=\"_blank\">ethereal-firebrand-132</a></strong> to <a href='https://wandb.ai/nov05/udacity-drlnd-matd3-unity-tennis' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nov05/udacity-drlnd-matd3-unity-tennis' target=\"_blank\">https://wandb.ai/nov05/udacity-drlnd-matd3-unity-tennis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nov05/udacity-drlnd-matd3-unity-tennis/runs/8yg7m0ph' target=\"_blank\">https://wandb.ai/nov05/udacity-drlnd-matd3-unity-tennis/runs/8yg7m0ph</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = MultiAgent(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500\tStep 8979\tScore: 0.00\tWindowed average Score: 0.02\n",
      "Episode 1000\tStep 17138\tScore: 0.00\tWindowed average Score: 0.00\n",
      "Episode 1500\tStep 24554\tScore: 0.00\tWindowed average Score: 0.02\n",
      "Episode 2000\tStep 35217\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 2500\tStep 47361\tScore: 0.00\tWindowed average Score: 0.04\n",
      "Episode 3000\tStep 60772\tScore: 0.00\tWindowed average Score: 0.05\n",
      "Episode 3500\tStep 75043\tScore: 0.00\tWindowed average Score: 0.06\n",
      "Episode 4000\tStep 89287\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 4500\tStep 103504\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 5000\tStep 117176\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 5500\tStep 130580\tScore: 0.10\tWindowed average Score: 0.04\n",
      "Episode 6000\tStep 143629\tScore: 0.00\tWindowed average Score: 0.06\n",
      "Episode 6500\tStep 157323\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 7000\tStep 171613\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 7500\tStep 185870\tScore: 0.00\tWindowed average Score: 0.05\n",
      "Episode 8000\tStep 200343\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 8500\tStep 214906\tScore: 0.10\tWindowed average Score: 0.06\n",
      "Episode 9000\tStep 228698\tScore: 0.00\tWindowed average Score: 0.05\n",
      "Episode 9500\tStep 241643\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 10000\tStep 255102\tScore: 0.00\tWindowed average Score: 0.04\n",
      "Episode 10500\tStep 267779\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 11000\tStep 280985\tScore: 0.00\tWindowed average Score: 0.05\n",
      "Episode 11500\tStep 294995\tScore: 0.00\tWindowed average Score: 0.06\n",
      "Episode 12000\tStep 308429\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 12500\tStep 321736\tScore: 0.10\tWindowed average Score: 0.04\n",
      "Episode 13000\tStep 335378\tScore: 0.10\tWindowed average Score: 0.06\n",
      "Episode 13500\tStep 347575\tScore: 0.00\tWindowed average Score: 0.07\n",
      "Episode 14000\tStep 359583\tScore: 0.10\tWindowed average Score: 0.05\n",
      "Episode 14500\tStep 371674\tScore: 0.00\tWindowed average Score: 0.05\n",
      "Episode 15000\tStep 383811\tScore: 0.00\tWindowed average Score: 0.05\n",
      "Episode 15500\tStep 398188\tScore: 0.09\tWindowed average Score: 0.09\n",
      "Episode 16000\tStep 416964\tScore: 0.00\tWindowed average Score: 0.08\n",
      "Episode 16500\tStep 435789\tScore: 0.10\tWindowed average Score: 0.10\n",
      "Episode 17000\tStep 456654\tScore: 0.10\tWindowed average Score: 0.12\n",
      "Episode 17500\tStep 476460\tScore: 0.20\tWindowed average Score: 0.12\n",
      "Episode 18000\tStep 497607\tScore: 0.10\tWindowed average Score: 0.13\n",
      "Episode 18500\tStep 518456\tScore: 0.20\tWindowed average Score: 0.12\n",
      "Episode 19000\tStep 541501\tScore: 0.30\tWindowed average Score: 0.15\n",
      "Episode 19500\tStep 571474\tScore: 0.20\tWindowed average Score: 0.16\n",
      "Episode 20000\tStep 611332\tScore: 0.30\tWindowed average Score: 0.19\n",
      "Episode 20500\tStep 658293\tScore: 0.10\tWindowed average Score: 0.28\n",
      "Episode 20938\tStep 715297\tScore: 2.60\tWindowed average Score: 0.51\n",
      "Reached average score of 0.51 between episode 20839 and episode 20938\n",
      "Episode 21000\tStep 731133\tScore: 2.60\tWindowed average Score: 0.60\n",
      "Episode 21500\tStep 908269\tScore: 2.20\tWindowed average Score: 0.95\n",
      "Episode 21761\tStep 1000321\tScore: 0.90\tWindowed average Score: 0.77CPU times: total: 5h 45min 26s\n",
      "Wall time: 16h 37min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores = agent.train()\n",
    "save_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ðŸŸ¢ The environment is solved.  \n",
    "```text\n",
    "Episode 20938\tStep 715297\tScore: 2.60\tWindowed average Score: 0.51\n",
    "Reached average score of 0.51 between episode 20839 and episode 20938\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_scores(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since episodes can get terminated early, here we plot scores against the number of trianing steps instead of number of episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_scores():\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = fig.add_subplot(111)\n",
    "    \n",
    "    plt.plot(*zip(*scores))\n",
    "\n",
    "    score_window = collections.deque(maxlen=100)\n",
    "    windowed_average_scores = []\n",
    "    for step, score in scores:\n",
    "        score_window.append(score)\n",
    "        windowed_average_scores.append((step, numpy.mean(score_window)))\n",
    "\n",
    "    plt.plot(*zip(*windowed_average_scores))\n",
    "    plt.plot(\n",
    "        list(map(lambda pair: pair[0], scores)),\n",
    "        [0.5] * len(scores),\n",
    "        \":\"\n",
    "    )\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Step #')\n",
    "    plt.show()\n",
    "\n",
    "plot_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can see how the agent performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8950000135228038"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## trained 1e6 steps, test 1 episode, score 0.8950000135228038\n",
    "agent.run_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 4\tStep 1001603\tScore: 2.60\tWindowed average Score: 0.85\n",
      "Reached average score of 0.85 between episode 1 and episode 4\n",
      "Episode 500\tStep 1172044\tScore: 0.10\tWindowed average Score: 1.16\n",
      "Episode 1000\tStep 1358847\tScore: 0.40\tWindowed average Score: 0.68\n",
      "Episode 1500\tStep 1501665\tScore: 1.40\tWindowed average Score: 0.81\n",
      "Episode 2000\tStep 1660344\tScore: 0.30\tWindowed average Score: 0.75\n",
      "Episode 2500\tStep 1818565\tScore: 2.60\tWindowed average Score: 1.22\n",
      "Episode 2557\tStep 1838719\tScore: 2.60\tWindowed average Score: 0.96"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## load saved model if neccessary\n",
    "# agent = MultiAgent(env)\n",
    "# agent.load(steps_offset=1e6)\n",
    "\n",
    "## train more steps if neccessary\n",
    "scores = agent.train(max_steps=int(1e6))\n",
    "save_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trained 2e6 steps, test 1 episode, score\n",
    "agent.run_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(scores)\n",
    "# plot_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load the \"best\" agent found during the training process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.600000038743019"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.load()\n",
    "agent.run_episode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "This environment stabalizes easily no only because the two agents are cooperating rather than competing with each other, but their local observations are also arguably sufficient for them to make decisions without caring much about what the other agent is doing. It would be interesting to try on the original Unity Tennis environment where the two agents are adversaries.\n",
    "\n",
    "A major challenge of this environment is the sparsity of the rewards, which can easily cause training progress to stagnate, especially in the early training phase. It would be interesting to experiment with reward shaping techniques to alleviate this issue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- Lowe, R., Wu, Y., Tamar, A., Harb, J., Abbeel, P., & Mordatch, I. (2017). Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments. https://arxiv.org/abs/1706.02275\n",
    "- Lillicrap, T. P. et al. (2015) â€˜Continuous control with deep reinforcement learningâ€™. Available at: http://arxiv.org/abs/1509.02971\n",
    "- Fujimoto, S., van Hoof, H. and Meger, D. (2018) â€˜Addressing Function Approximation Error in Actor-Critic Methodsâ€™. Available at: https://arxiv.org/abs/1802.09477\n",
    "- Ackermann, J., Gabler, V., Osa, T., & Sugiyama, M. (2019). Reducing Overestimation Bias in Multi-Agent Domains Using Double Centralized Critics. https://arxiv.org/abs/1910.01465\n",
    "- Schaul, T. et al. (2015) â€˜Prioritized Experience Replayâ€™. Available at: http://arxiv.org/abs/1511.05952\n",
    "- Andrychowicz, M., Raichuk, A., StaÅ„czyk, P., Orsini, M., Girgin, S., Marinier, R., Hussenot, L., Geist, M., Pietquin, O., Michalski, M., Gelly, S., & Bachem, O. (2020). What Matters In On-Policy Reinforcement Learning? A Large-Scale Empirical Study. https://arxiv.org/abs/2006.05990"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
